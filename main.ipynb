{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1 (Landing & Bronze)\n",
    "Aquisição de Dados e Armazenamento de Dados em PostgreSQL.\n",
    "- Baixe o conjunto de dados \"Inside Airbnb\" do Rio de Janeiro da fonte oficial (http://insideairbnb.com/) e promova uma estruturação simples nos dados.\n",
    "- Crie um banco de dados PostgreSQL para armazenar os dados brutos das 3 tabelas (\"Listing\", \"Reviews\" e Calendar\") na camada \"bronze\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Landing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.etl import Landing\n",
    "\n",
    "url = [\n",
    "    'https://data.insideairbnb.com/brazil/rj/rio-de-janeiro/2023-12-26/data/listings.csv.gz',\n",
    "    'https://data.insideairbnb.com/brazil/rj/rio-de-janeiro/2023-12-26/data/calendar.csv.gz',\n",
    "    'https://data.insideairbnb.com/brazil/rj/rio-de-janeiro/2023-12-26/data/reviews.csv.gz'\n",
    "]\n",
    "landing_step = Landing(landing_path='data/landing')\n",
    "landing_step.extract(url=url)\n",
    "landing_step.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from modules.utils import clean_path\n",
    "from modules.database import PostgreSQL\n",
    "\n",
    "## Criação de base de dados\n",
    "database = PostgreSQL() # Inicializando a classe com as variaveis de conexão com o banco\n",
    "database.create_database('datalake') # Criando o database datalake\n",
    "\n",
    "## Criação dos Schema\n",
    "try:\n",
    "    print(\"Iniciando a criação dos schemas bronze, silver e gold\")\n",
    "\n",
    "    database.create_schema(schema_name='bronze',database='datalake')\n",
    "    database.create_schema(schema_name='silver',database='datalake')\n",
    "    database.create_schema(schema_name='gold',database='datalake')\n",
    "\n",
    "    print(\"Fim da criação dos schemas\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao criar os schemas: {e}\")\n",
    "    raise e\n",
    "\n",
    "## Inserção dos dataframes\n",
    "try:\n",
    "    print(\"Inicio do carregamento de dados (Bronze)\")\n",
    "\n",
    "    data_path = './data/landing' # Define onde estão os CSVs\n",
    "    df_listings = pd.read_csv(os.path.join(data_path,'listings.csv')) # Lê o csv e transforma em um dataframe Python\n",
    "    database.insert_dataframe(dataframe=df_listings,table_name='listings',schema='bronze',database='datalake',if_exists='append') # Insere o Dataframe no banco de dados\n",
    "    del df_listings # Libera o espaço que a variável consome na memória RAM\n",
    "\n",
    "    df_reviews = pd.read_csv(os.path.join(data_path,'reviews.csv')) # Lê o csv e transforma em um dataframe Python\n",
    "    database.insert_dataframe(dataframe=df_reviews,table_name='reviews',schema='bronze',database='datalake',if_exists='append') # Insere o Dataframe no banco de dados\n",
    "    del df_reviews # Libera o espaço que a variável consome na memória RAM\n",
    "\n",
    "    df_calendar = pd.read_csv(os.path.join(data_path,'calendar.csv')) # Lê o csv e transforma em um dataframe Python\n",
    "    database.insert_dataframe(dataframe=df_calendar,table_name='calendar',schema='bronze',database='datalake',if_exists='append') # Insere o Dataframe no banco de dados\n",
    "    del df_calendar # Libera o espaço que a variável consome na memória RAM\n",
    "\n",
    "    clean_path(path='data/landing') # Limpando os arquivos CSVs\n",
    "\n",
    "    print(\"Fim do carregamento de dados (Bronze)\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao inserir os dados: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2 (Silver)\n",
    "**Data Clean - Camada Silver**\n",
    "\n",
    "- Identifique e lide com valores ausentes, duplicatas e outliers nos dados brutos da camada \"bronze\".\n",
    "- Padronize e limpe os nomes das colunas, convertendo-os em um formato consistente.\n",
    "- Realize uma limpeza textual em campos, como descrições de propriedades, removendo caracteres especiais e erros de digitação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from modules.database import PostgreSQL\n",
    "\n",
    "# Importanddo a tabela\n",
    "database = 'datalake'\n",
    "df_silver_listings = pd.read_sql_table(table_name='listings',schema='bronze',con=PostgreSQL().create_connection(database=database),index_col='index')\n",
    "\n",
    "# Alterar tipo de coluna para datetime64[ns] para colunas: 'last_scraped', 'host_since' e 3 outras colunas\n",
    "df_silver_listings = df_silver_listings.astype({'last_scraped': 'datetime64[ns]', 'host_since': 'datetime64[ns]', 'calendar_last_scraped': 'datetime64[ns]', 'last_review': 'datetime64[ns]', 'first_review': 'datetime64[ns]'})\n",
    "\n",
    "# Alterar tipo de coluna para category para coluna: 'source'\n",
    "df_silver_listings = df_silver_listings.astype({'source': 'category'})\n",
    "\n",
    "# Removendo caracteres especiais das colunas 'neighborhood_overview' e 'host_about'\n",
    "import re\n",
    "df_silver_listings['neighborhood_overview'] = df_silver_listings['neighborhood_overview'].apply(lambda x: None if x is None else re.sub(r'[^a-zA-Z0-9\\s.()]','',x))\n",
    "df_silver_listings['host_about'] = df_silver_listings['host_about'].apply(lambda x: None if x is None else re.sub(r'[^a-zA-Z0-9\\s.()]','',x))\n",
    "\n",
    "# Remover colunas 100% vazias\n",
    "df_silver_listings = df_silver_listings.dropna(axis=1,how='all')\n",
    "\n",
    "# Removendo linhas duplicadas\n",
    "df_silver_listings = df_silver_listings.drop_duplicates()\n",
    "\n",
    "# Substituir todas as instâncias de \"t\" por \"1\" nas colunas: 'host_is_superhost', 'host_has_profile_pic' e 3 outras colunas\n",
    "colunas_a_ser_tratadas = ['host_is_superhost','host_has_profile_pic','host_identity_verified','instant_bookable','has_availability']\n",
    "for coluna in colunas_a_ser_tratadas:\n",
    "    df_silver_listings[coluna] = df_silver_listings[coluna].apply(lambda x: 1 if str(x).lower() == 't' else 0)\n",
    "\n",
    "# Alterar tipo de coluna para category para coluna: 'host_response_time'\n",
    "df_silver_listings = df_silver_listings.astype({'host_response_time': 'category'})\n",
    "\n",
    "# Convertendo as colunas host_response_rate e host_acceptance_rate em int\n",
    "colunas_a_serem_convertidas = ['host_response_rate','host_acceptance_rate']\n",
    "for coluna in colunas_a_serem_convertidas:\n",
    "    df_silver_listings[coluna] = df_silver_listings[coluna].apply(lambda x: 0 if x is None else int(x.replace(\"%\",'')))\n",
    "\n",
    "# Tratando a coluna bathrooms_text\n",
    "df_silver_listings['bathrooms_text'] = df_silver_listings['bathrooms_text'].fillna('0 bath') # Tratando vazios\n",
    "df_silver_listings['num_of_bathrooms'] = df_silver_listings['bathrooms_text'].str.extract(r\"(\\d+(?:\\.\\d+)?)\", expand=False).astype(float).fillna(0.0) # Retirando os valores númericos da coluna\n",
    "df_silver_listings['type_of_bathroom'] = df_silver_listings['bathrooms_text'].str.replace(r'(\\d+\\.?\\d*)', '', regex=True) # Defina o tipo de banheiro\n",
    "df_silver_listings['type_of_bathroom'] = df_silver_listings['type_of_bathroom'].str.replace(r's?$', '', regex=True).apply(lambda x: x.strip()) # Remova 's' do final de 'baths e traz\n",
    "df_silver_listings = df_silver_listings.astype({'type_of_bathroom':'category'}) # Mudando o tipo da coluna type_of_bathroom\n",
    "df_silver_listings.drop(columns='bathrooms_text',inplace=True) # Dropando a coluna de origem\n",
    "\n",
    "# Substituir valores ausentes por 0 nas colunas: 'review_scores_rating', 'review_scores_accuracy' e 6 outras colunas\n",
    "df_silver_listings = df_silver_listings.fillna({'review_scores_rating': 0, 'review_scores_accuracy': 0, 'review_scores_cleanliness': 0, 'review_scores_checkin': 0, 'review_scores_communication': 0, 'review_scores_location': 0, 'review_scores_value': 0, 'reviews_per_month': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from modules.database import PostgreSQL\n",
    "\n",
    "# Importanddo a tabela\n",
    "database = 'datalake'\n",
    "df_silver_reviews = pd.read_sql_table(table_name='reviews',schema='bronze',con=PostgreSQL().create_connection(database=database),index_col='index')\n",
    "\n",
    "# Alterar tipo de coluna para datetime64[ns] para coluna: 'date'\n",
    "df_silver_reviews = df_silver_reviews.astype({'date': 'datetime64[ns]'})\n",
    "\n",
    "# Substituir todas as instâncias de \"<br/>\" por \"\\n\" na coluna: 'comments'\n",
    "df_silver_reviews['comments'] = df_silver_reviews['comments'].str.replace(\"<br/>\", \"\\n\", case=False, regex=False)\n",
    "\n",
    "# Remover espaço em branco à direita e à esquerda na coluna: 'reviewer_name'\n",
    "df_silver_reviews['reviewer_name'] = df_silver_reviews['reviewer_name'].str.strip()\n",
    "\n",
    "# Remover linhas duplicadas em todas as colunas\n",
    "df_silver_reviews = df_silver_reviews.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from modules.database import PostgreSQL\n",
    "\n",
    "# Importanddo a tabela\n",
    "database = 'datalake'\n",
    "df_silver_calendar = pd.read_sql_table(table_name='calendar',schema='bronze',con=PostgreSQL().create_connection(database=database),index_col='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 3 (Silver)\n",
    "**Data Quality - Camada Silver**\n",
    "\n",
    "- Defina métricas de qualidade de dados, como integridade, precisão e consistência para os dados da camada \"bronze\".\n",
    "- Implemente verificações para garantir que os dados da camada \"silver\" estejam em conformidade com essas métricas.\n",
    "- Estabeleça um sistema de monitoramento contínuo da qualidade dos dados da camada \"silver\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 4 (Silver)\n",
    "**Testes de Qualidade - Camada Silver**\n",
    "\n",
    "- Utilize a biblioteca Great Expectations para criar testes de qualidade automatizados que verifiquem as expectativas definidas para os dados da camada \"silver\".\n",
    "- Desenvolva testes que assegurem que os dados da camada \"silver\" atendam às regras de negócios e aos requisitos de qualidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# COLUNAS DATEIME\n",
      "A coluna 'last_scraped' é válida. (Tipo e Valor)\n",
      "A coluna 'host_since' é válida. (Tipo e Valor)\n",
      "A coluna 'calendar_last_scraped' é válida. (Tipo e Valor)\n",
      "A coluna 'last_review' é válida. (Tipo e Valor)\n",
      "A coluna 'first_review' é válida. (Tipo e Valor)\n",
      "\n",
      "# COLUNAS CATEGORICAS\n",
      "Os valores da coluna source, só contém valores esperados. (['city scrape', 'previous scrape'])\n",
      "Os valores da coluna room_type, só contém valores esperados. (['Entire home/apt', 'Private room', 'Shared room', 'Hotel room'])\n",
      "\n",
      "# COLUNAS BOOLEANAS\n",
      "A coluna 'host_is_superhost' é válida. (Tipo e Valor)\n",
      "A coluna 'host_has_profile_pic' é válida. (Tipo e Valor)\n",
      "A coluna 'host_identity_verified' é válida. (Tipo e Valor)\n",
      "A coluna 'instant_bookable' é válida. (Tipo e Valor)\n",
      "A coluna 'has_availability' é válida. (Tipo e Valor)\n",
      "\n",
      "# COLUNAS NÃO VAZIAS\n",
      "A coluna 'review_scores_rating' é válida. (Não tem valores nulos)\n",
      "A coluna 'review_scores_accuracy' é válida. (Não tem valores nulos)\n",
      "A coluna 'review_scores_cleanliness' é válida. (Não tem valores nulos)\n",
      "A coluna 'review_scores_checkin' é válida. (Não tem valores nulos)\n",
      "A coluna 'review_scores_communication' é válida. (Não tem valores nulos)\n",
      "A coluna 'review_scores_location' é válida. (Não tem valores nulos)\n",
      "A coluna 'review_scores_value' é válida. (Não tem valores nulos)\n",
      "A coluna 'reviews_per_month' é válida. (Não tem valores nulos)\n"
     ]
    }
   ],
   "source": [
    "import modules.utils as utils\n",
    "import great_expectations as gx\n",
    "\n",
    "gx_df_listings = gx.from_pandas(df_silver_listings)\n",
    "\n",
    "# Verificando os tipos das colunas\n",
    "print(\"# COLUNAS DATEIME\")\n",
    "colunas_datetime = ['last_scraped', 'host_since', 'calendar_last_scraped', 'last_review', 'first_review']\n",
    "utils.verifica_colunas_datetime(gx_df_listings, colunas_datetime)\n",
    "\n",
    "# Checando os valores Categóricos\n",
    "print(\"\\n# COLUNAS CATEGORICAS\")\n",
    "coluna_a_ser_analisada, valores_esperados = 'source', ['city scrape', 'previous scrape']\n",
    "utils.verificar_colunas_categoricas(gx_df_listings,coluna_a_ser_analisada, valores_esperados)\n",
    "\n",
    "coluna_a_ser_analisada, valores_esperados = 'room_type', ['Entire home/apt', 'Private room', 'Shared room', 'Hotel room']\n",
    "utils.verificar_colunas_categoricas(gx_df_listings,coluna_a_ser_analisada, valores_esperados)\n",
    "\n",
    "# Checando as colunas Booleanas\n",
    "print(\"\\n# COLUNAS BOOLEANAS\")\n",
    "colunas_booleanas = ['host_is_superhost','host_has_profile_pic','host_identity_verified','instant_bookable','has_availability']\n",
    "utils.verificar_colunas_booleanas(gx_df=gx_df_listings,list_of_columns=colunas_booleanas)\n",
    "\n",
    "# Verificando nulos\n",
    "print(\"\\n# COLUNAS NÃO VAZIAS\")\n",
    "colunas_nao_vazias = ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'reviews_per_month']\n",
    "utils.verificar_collunas_com_none(gx_df=gx_df_listings,list_of_columns=colunas_nao_vazias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
